{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a989188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# HEART DISEASE DETECTION PROJECT - FINAL ADVANCED VERSION\n",
    "# Includes: CV, SHAP, Error Analysis, PDF Report, Joblib\n",
    "# ------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.pagesizes import A4\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26bc03d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: (1888, 14)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 1: Load Dataset\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# data = pd.read_csv(\"combined_heart_dataset.csv\")  # UCI Dataset\n",
    "\n",
    "data = pd.read_csv(\"cleaned_merged_heart_dataset.csv\")\n",
    "print(f\"Dataset Loaded: {data.shape}\")\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c57e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 2: Preprocessing\n",
    "# ------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c9a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 3: Define Models + Hyperparameters\n",
    "# ------------------------------------------------------\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\"C\": [0.1, 1, 10]}),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), {\"n_estimators\": [100, 200]}),\n",
    "    \"Gradient Boosting\": (GradientBoostingClassifier(random_state=42), {\"n_estimators\": [100, 200]}),\n",
    "    \"XGBoost\": (XGBClassifier(eval_metric='logloss', random_state=42), {\"n_estimators\": [100, 200]}),\n",
    "    \"SVM\": (SVC(probability=True), {\"C\": [0.1, 1, 10], \"kernel\": [\"rbf\", \"linear\"]}),\n",
    "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\": [3, 5, 7, 9]})\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5a0fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Best CV Accuracy: 0.7497 ± 0.0419\n",
      "\n",
      "Training Random Forest...\n",
      "Best CV Accuracy: 0.9656 ± 0.0100\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Best CV Accuracy: 0.9364 ± 0.0077\n",
      "\n",
      "Training XGBoost...\n",
      "Best CV Accuracy: 0.9563 ± 0.0057\n",
      "\n",
      "Training SVM...\n",
      "Best CV Accuracy: 0.9384 ± 0.0095\n",
      "\n",
      "Training KNN...\n",
      "Best CV Accuracy: 0.9384 ± 0.0173\n",
      "\n",
      "--- Model Results with CV ---\n",
      "                 Model  CV Accuracy Mean    CV Std  Test Accuracy  Precision  \\\n",
      "1        Random Forest          0.965563  0.009956       0.981481   0.974874   \n",
      "3              XGBoost          0.956291  0.005697       0.976190   0.965174   \n",
      "2    Gradient Boosting          0.936424  0.007666       0.952381   0.954082   \n",
      "4                  SVM          0.938411  0.009505       0.933862   0.917073   \n",
      "5                  KNN          0.938411  0.017345       0.944444   0.910798   \n",
      "0  Logistic Regression          0.749669  0.041864       0.748677   0.724444   \n",
      "\n",
      "     Recall        F1       AUC  \n",
      "1  0.989796  0.982278  0.999047  \n",
      "3  0.989796  0.977330  0.998402  \n",
      "2  0.954082  0.954082  0.990301  \n",
      "4  0.959184  0.937656  0.977377  \n",
      "5  0.989796  0.948655  0.974672  \n",
      "0  0.831633  0.774347  0.805338  \n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 4: Train Models + Evaluate with Cross-Validation\n",
    "# ------------------------------------------------------\n",
    "\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring='accuracy', n_jobs=-1, return_train_score=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    mean_cv_score = grid.cv_results_['mean_test_score'][grid.best_index_]\n",
    "    std_cv_score = grid.cv_results_['std_test_score'][grid.best_index_]\n",
    "    print(f\"Best CV Accuracy: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV Accuracy Mean\": mean_cv_score,\n",
    "        \"CV Std\": std_cv_score,\n",
    "        \"Test Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"AUC\", ascending=False)\n",
    "print(\"\\n--- Model Results with CV ---\")\n",
    "print(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75adefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best Model Saved: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 5: Save All Models Using Joblib\n",
    "# ------------------------------------------------------\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    file_name = f\"{name.replace(' ', '_').lower()}_model.pkl\"\n",
    "    joblib.dump(model, file_name)\n",
    "\n",
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_model = best_models[best_model_name]\n",
    "joblib.dump(best_model, \"best_heart_model.pkl\")\n",
    "print(f\"\\n✅ Best Model Saved: {best_model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51b9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 6: Visualize CV vs Test Accuracy\n",
    "# ------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(results_df[\"Model\"], results_df[\"CV Accuracy Mean\"], alpha=0.6, label='CV Accuracy')\n",
    "plt.bar(results_df[\"Model\"], results_df[\"Test Accuracy\"], alpha=0.6, label='Test Accuracy')\n",
    "plt.title(\"Cross-Validation vs Test Accuracy by Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cv_vs_test_accuracy.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ea84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 7: ROC Curve Comparison\n",
    "# ------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, model in best_models.items():\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc_score(y_test, y_prob):.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_comparison.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d52366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating SHAP values...\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 8: SHAP Explainability (Using XGBoost)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "print(\"\\nCalculating SHAP values...\")\n",
    "xgb_model = best_models[\"XGBoost\"]\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer(X_test)\n",
    "joblib.dump(shap_values, \"shap_values.pkl\")\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary.png\")\n",
    "plt.close()\n",
    "\n",
    "# SHAP bar plot\n",
    "shap.plots.bar(shap_values, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_bar.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d8e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Misclassified samples: 7 / 378\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 9: Error and High-Error Analysis\n",
    "# ------------------------------------------------------\n",
    "\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# Misclassified samples\n",
    "test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_df[\"Actual\"] = y_test.values\n",
    "test_df[\"Predicted\"] = y_pred_final\n",
    "errors = test_df[test_df[\"Actual\"] != test_df[\"Predicted\"]]\n",
    "joblib.dump(errors, \"error_samples.pkl\")\n",
    "\n",
    "print(f\"\\nMisclassified samples: {len(errors)} / {len(y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7d58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating PDF report...\n",
      "\n",
      "✅ Report generated successfully: Heart_Disease_Model_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Step 10: PDF Report Generation\n",
    "# ------------------------------------------------------\n",
    "\n",
    "print(\"\\nGenerating PDF report...\")\n",
    "\n",
    "doc = SimpleDocTemplate(\"Heart_Disease_Model_Report.pdf\", pagesize=A4)\n",
    "styles = getSampleStyleSheet()\n",
    "story = []\n",
    "\n",
    "story.append(Paragraph(\"<b>Heart Disease Detection Project - Summary Report</b>\", styles[\"Title\"]))\n",
    "story.append(Spacer(1, 12))\n",
    "story.append(Paragraph(f\"<b>Best Model:</b> {best_model_name}\", styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 8))\n",
    "\n",
    "story.append(Paragraph(\"<b>Cross-Validation Performance (5-Fold):</b>\", styles[\"Heading2\"]))\n",
    "story.append(Paragraph(results_df[[\"Model\", \"CV Accuracy Mean\", \"CV Std\"]].to_html(index=False), styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>Model Performance Summary (Test Results):</b>\", styles[\"Heading2\"]))\n",
    "story.append(Paragraph(results_df[[\"Model\", \"Test Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"]].to_html(index=False), styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>CV vs Test Accuracy Comparison:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Image(\"cv_vs_test_accuracy.png\", width=400, height=300))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>ROC Curve Comparison:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Image(\"roc_comparison.png\", width=400, height=300))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>SHAP Global Feature Importance:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Image(\"shap_bar.png\", width=400, height=300))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>SHAP Feature Impact Summary:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Image(\"shap_summary.png\", width=400, height=300))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>Confusion Matrix (Best Model):</b>\", styles[\"Heading2\"]))\n",
    "story.append(Image(\"conf_matrix.png\", width=400, height=300))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>Error Analysis:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Paragraph(f\"Total Misclassifications: {len(errors)} out of {len(y_test)}\", styles[\"Normal\"]))\n",
    "story.append(Paragraph(f\"<b>Sample Misclassified Records:</b><br/>{errors.head().to_html(index=False)}\", styles[\"Normal\"]))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "story.append(Paragraph(\"<b>Interpretation:</b>\", styles[\"Heading2\"]))\n",
    "story.append(Paragraph(\"\"\"\n",
    "The XGBoost model demonstrated the highest accuracy and AUC across both CV and test evaluations.\n",
    "Cross-validation results confirmed model stability, with low standard deviation across folds.\n",
    "SHAP analysis identified 'thalach', 'oldpeak', and 'ca' as dominant predictors of heart disease risk.\n",
    "Misclassifications mostly occurred in borderline cholesterol and age ranges,\n",
    "indicating potential benefit from adding more detailed health indicators.\n",
    "\"\"\", styles[\"Normal\"]))\n",
    "\n",
    "doc.build(story)\n",
    "print(\"\\n✅ Report generated successfully: Heart_Disease_Model_Report.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
